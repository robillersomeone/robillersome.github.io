<!DOCTYPE html>
<head>
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-172491062-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-172491062-1');
  </script>
  <title> - distributions </title>
  <meta charset="utf-8">
  <meta property="og:title" content="ðŸŒ¦">
  <meta name="viewport" content="width=device-width">
  <meta property="og:image" content="../assets/imgs/doodles.png">
  <link rel="shortcut icon" type="image/x-icon" href="../assets/imgs/favicon.ico">
  <link href="https://fonts.googleapis.com/css2?family=Raleway:wght@300;400;600&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="../assets/style.css">
</head>
<body id="top">
  <header>
    <div id="starting">
      <div><a href="../ns-the-details/">the details</a></div>
    </div>
  </header>
    <!-- main title -->
    <h1 id="minimal">hi</h1> 
    <h2>this site visually explores the relationship between distributions</h2>
    <!-- <h2>start scrolling to see</h2> -->
    <div id="container" class="container-1">
        <div id="graph"></div>
        <div id="sections">
            <div>
                <!-- title content for left scroll part - gamma(1,2) -->
                <h3>let's start with a function</h3>
                <p> 
                  the <strong>gamma</strong> function to be exact. 
                  <br> 
                  <br>
                  which looks like this equation.
                </p>
                <!-- paragraph for the equation for the gamma function -->
                <p> &#x393; (n) = (n-1)! </p>
                <p> 
                  that function along with euler's number, fractions, and some exponents make a distribution with a shape and scale. 
                  we call the shape and scale the parameters of the distribution and we call the distribution
                  the <strong>gamma distribution</strong>.
                </p>
                <!-- might add a break -->
                <p>
                  when the  <span class="mono">shape=1</span> and  <span class="mono">scale=2</span> 
                  <br>
                  we get this graph. 
                </p>
            </div>
            <div>
                <!-- second paragraph - gamma(2,2) -->
                <h3> the distribution changes as the parameters change</h3>
                <p>add one to the <span class="mono">shape</span> and  <span class="mono">scale</span> 
                and we get a very different graph. </p>
            </div>
            <div>
                <!-- third paragraph - gamma(3,2) -->
                <h3>the distribution flattens</h3>
                <p>
                  as the shape and scale increase. 

                </p>             
                <p>
                  here the <span class="mono">shape=3</span> and <span class="mono">scale=2</span>
                </p>
                <p>
                  the gamma distribution is a building block for others - let's take a look at the <strong>exponential distribution</strong>.
                </p>

            </div>
            <div>
              <!-- fourth paragraph - gamma(1,2) -->
              <h3>the exponential distribution</h3>
              <p> 
                brings us back to the first graph.
              </p>
              <p>
                an exponential distribution is a type of gamma distribution 
                where the <span class="mono">shape</span> parameter is set to one.
              </p>
              <p>
              </p>
            </div>
            <div>
                <!-- fifth paragraph - exp(1) -->
                <!-- probably gonna go expo(1) because rate/scale issue -->
                <h3>
                  the exponential distribution moves as the <span class="mono">scale</span> changes
                </h3>
                <p> 
                  <!-- add the fact rate is inverse of scale -->
                  however, when we think of the exponential distribution moving we talk about the <span class="mono">rate</span> changing. 
                  <br> 
                  <br>
                  this is because thinking of <span class="mono">rate</span> as the parameter in exponential distributions
                  lets us solve problems.
                  <br>
                  <br>
                  the <span class="mono">rate</span> is equal the inverse of the <span class="mono">scale</span> in the gamma distribution.
                </p>
                <p>
                  here is an <strong>exponential distribution</strong> with <span class="mono">rate=1</span>
                </p>
            </div>
            <div>
              <h3>
                <!-- sixth paragraph - data erlang(2,2) -->
                getting back to gamma
              </h3>
              <p> 
                while the exponential distribution lets us solve some problems, we can solve new ones if we add a bunch of 
                exponential distributions together.
              </p>
              
              <p>this graph is made by <strong>adding</strong> two exponential distributions together, both with <span class="mono">rate=.5</span></p>
              
              <p>
                
                since the <span class="mono">shape</span> of an exponential distribution is always one, 
                the <span class="mono">shape</span> parameter of the gamma distribution 
                that comes from adding exponentials will always be a positive whole number.
                <br>
                <br>
                when that happens we call it an <strong>erlang distribution</strong>, which you can see
                with a <span class="mono">shape=2</span> and  <span class="mono">scale=2</span>
              </p>
            </div>
            <div>
              <h3>
                <!-- seventh paragraph - chi(6) -->
                one more gamma 
              </h3>
              <p> 
                we can make one more distribution by picking certain values for our
                gamma function, the <strong>chi-squared distribution</strong> .
              </p>
              <p>
                this one is seen in stats classes when doing the test for indepedence to see if two or more classes are mutually exclusive, it has one
                parameter, <span class="mono">degrees of freedom</span>. here the 
                <span class="mono">degrees of freedom=6</span>
              </p>
              <p>
                to make the chi-squared distribution from the gamma distribution, we set the <span class="mono">scale</span>
                to two and divide the  <span class="mono">shape</span> by two.
                <!-- the <span class="mono">shape/2</span> is equal to <span class="mono">degrees of freedom=6</span> -->
              </p>
            </div>
            <div>
              <h3>
                <!-- eighth paragraph - chi (8) -->
                tying it together
              
              </h3>
              <p> 
                <!-- end this section with recap of expo and erlang and chi
                which are all specific parameterization of the gamma distribution. -->
                the three distributions we made - the exponential, erlang, and chi-squared
                are all specific parameterizations of the gamma distribution. 
              </p>
              <p>
                <!-- expo is a poisson process, and thank erlang for better calls -->
                <strong>exponential</strong> predicts the time until something happens, 
                <strong>erlang</strong> is used to predict how long you'll wait in a queue,
                and <strong>chi-squared</strong> looks at indepedence between groups.
              </p>
              <p>
                next, we'll build distributions with multiple gamma functions.
              </p>  
            </div>
            <div>
              <h3>
                <!-- ninth paragraph - beta(4,6) -->
                the second distribution
              </h3>
              <p> 
                <!-- 
                  now, instead of picking special values for the parameters of the gamma distribution, let's 
                  use multiple distributions
                 -->
                 the <strong>beta distribtuion</strong> is made of using two independent gamma distributions. 
              </p>
              <p> beta(a, b) = gamma(a, Î¸) / ( gamma(a,Î¸) + gamma(b, Î¸) )</p>
              <p>
                where a and b are the two parameters of the beta distribution called alpha and beta. 
                here we set <span class="mono">alpha=4, beta=6</span>.
              </p>
              <p>
                the beta distribution looks larger on the graph, because it has a different support (x values). 
                it is defined from <span class="mono">[0,1]</span>, while the gamma distribution is defined from
                <span class="mono">[0,âˆž]</span>, so we zoomed in a little.
              </p>
            </div>
            <div>
              <h3>
                <!-- tenth paragraph - beta(3,2) -->
                functionally speaking
              </h3>
              <p> 
                the beta distribution is named because of the <strong>beta function</strong>. the beta function has two parameters
                and can be written in terms of the gamma function. 
              </p>
              <p> beta(x, y) = ( &#x393; (x) * &#x393; (y) ) / &#x393; (x + y)</p>
              <p>
                in this graph we changed the the parameters of the distribution to <span class="mono">alpha=3, beta=2</span>.
              </p>
            </div>
            <div>
              <h3>
                <!-- eleventh paragraph - uniform beta(1,1) -->
                starting from scratch
              </h3>
              <p> 
                if we set the two parameters of the beta distribution to  <span class="mono">alpha=1, beta=1</span>
                we get a horizontal line, which is called the <strong>uniform distribution</strong>.
              </p>
              <p> we can interpret a uniform distribution as every outcome being equally likely. 
                because of this, we use the uniform parametrization of the beta distribution 
                as a common starting point or conjugate prior in bayesian statistics.
              </p>
            </div>
            <div>
              <h3>
                <!-- twelfth paragraph - arcsin beta(.5,.5) -->
                another starting point
              </h3>
              <p> 
                the <strong> arcsin distribution</strong> is a common prior distribution in bayesian statistics as well.
                it is just another specific parametrization
                of the beta distribution with <span class="mono">alpha=.5, beta=.5</span>
              </p>
            </div>
            <div>
              <h3>
                <!-- thirteenth paragraph - kumaraswamy(5,1) -->
                almost beta
              </h3>
              <p> 
                the <strong> kumaraswamy distribution</strong> is very similar to the <strong>beta distribution</strong> with two shape parameters,
                but we don't use the beta function to make the probability density function, unlike the beta distribution.
              </p>
              <p>
                also, another way to think about the parameterization of a <strong>uniform distribution</strong> is a as <strong> 
                kumaraswamy distribution</strong> with <span class="mono">alpha=1, beta=1</span>
                , here we set <span class="mono">alpha=5, beta=1</span>
              </p>
            </div>
            <div>
              <h3>
                <!-- fourteenth paragraph - laplace(0,1) -->
                going all over laplace
              </h3>
              <p> 
                 if we divide two standard uniform distributions both with parameters <span class="mono">alpha=0, beta=1</span> and then take the log, we get the <strong>laplace distribution</strong>.
              </p>
              <p>laplace(0,1) = log( uniform(0,1) / uniform(0,1) )</p>
              <p> 
                the <strong>laplace distribution</strong> has two parameters, here they are <span class="mono">location=10, scale=1</span>. if the <span class="mono">location=0</span> then we would only see the right side of the peak.
              </p>
            </div>
            <div>
              <h3>
                <!-- fifteenth paragraph - f(2,2) -->
                testing it out 
              </h3>
              <p> 
                using two laplace distributions, we can build another distribution by dividing them. This makes a common distribution in statistical testing - the <strong>f distribution</strong>.        
              </p>
              <p> 
                the <strong>f distribution</strong> is known as a ratio distribution ~ another common way to make it is by taking the ratio of two <strong>chi-squared distributions</strong> (which are really just gamma distributions). 
                it has two parameters, which are both <span class="mono">degrees of freedom</span>, here both are <span class="mono">degrees of freedom=2</span>
              </p>
              <p>while the <strong>chi-squared distribution</strong> is used in the test for indepedence, with the <strong>f distribution</strong> 
                we can do analysis of variance (called ANOVA for short) and the f-test for finding the best model in a linear regression.
              </p> 
            </div>
            <div>
              <h3>
                <!-- sixteenth paragraph - z(5,2) -->
                test number 2
              </h3>
              <p> 
                taking the log of the <strong>f distribution</strong> and dividing it by 2 we can make the <strong>fisher's z distribution</strong>.        
                the <strong>fisher's z distribution</strong>, also has two parameters like the 
                f distribution, <span class="mono">degrees of freedom</span>, known as <span class="mono">degree 1</span> and <span class="mono">degree 2</span>. 
               
              </p>
              <p>
                <strong>fisher's z</strong> (degree 1, degree 2) = log ( <strong>f</strong> (degree 1, degree 2) ) / 2
              </p>
              <p> 
                here <span class="mono">degree 1=5, degree 2=2</span>. an important note - this distribution is not used in a z-test,
                for those we use a normal distribution, which is just around the corner.
              </p>
          
            </div>
            
            <div>
              <h3>
                <!-- seventeenth paragraph - rayleigh(1) -->
                raylly?
              </h3>
              <p> 
                  the <strong>rayleigh distribution</strong> has one parameter, the <span class="mono">scale</span>, here the <span class="mono">scale=1</span>. when that happens it can be thought of as a case of the chi-squared distribution where the <span class="mono">degrees of freedom=2</span>
              </p>
              <p>
                when looking at wind speed, the magnitude of the speed tends to follow a <strong>rayleigh distribution</strong>, and generally this distribution is helpful when looking for the magnitude of components.
              </p>
              <p> 
                the <strong>laplace</strong>, <strong>f</strong>, <strong>fisher's z</strong>, and <strong>rayleigh distributions</strong> can all by made by subtracting, dividing, or taking a square root of a specific parameterization of the <strong>gamma distribution</strong>.
              </p>
            </div>
            <div>
              <h3>
                <!-- eighteenth paragraph - generalized normal distribution(2.5,1, 4)??? -->
                generally speaking
              </h3>
              <p>
                the laplace distribution we made earlier is a case of the <strong>generalied normal distribution</strong>,
                which has three parameters, <span class="mono">location, scale,</span> and <span class="mono">shape</span>
              </p>
              <p>
                here the <span class="mono">location=2.5, scale=1,</span> and <span class="mono">shape=4</span>
              </p>
              <p>      
                we call the laplace distribution we made earlier is a parameterization of the <strong>generalied normal distribution</strong>
                when  the <span class="mono">shape=1</span>, 
                along with laplace the normal distribution is another parameterization of the <strong>generalied normal distribution</strong> 
                when  the <span class="mono">shape=2</span>,
                but before we get there let's talk transformations and sampling.
              </p>
            </div>
            <div>
              <h3>
                <!-- seventeenth paragraph -  cauchy(2.5,2) -->
                <!-- another uniform transformation -->
                uniform transformed
              </h3>
              <p>
                if we take a fourier transform of laplace we get a <strong>cauchy(0,1)</strong>, 
                we can also make the cauchy distribution from transforming a uniform distribution.
              </p>
              <p> 
                cauchy(0,1) = tan( Ï€ (uniform - .5) )
              </p>
              <p>
                the parameters of for the <strong>cauchy distribution</strong> are <span class="mono">location</span> 
                and <span class="mono">scale</span>, here the <span class="mono">location=0 scale=2</span>.
                the tails of the <strong>cauchy distribution</strong> are larger than the <strong>normal distribution</strong>.
              </p>
            </div>
            <div>
              <h3>
                <!-- eighteenth paragraph -  t(1) -->
                taking a sample
              </h3>
              <p>
                setting <strong>cauchy(0,1)</strong> gets us to another popular distribution in statistical testing, 
                the <strong>t-distribution</strong> with one parameter <span class="mono">degrees of freedom</span>.
              </p>
              <p> 
                the <strong>t-distribution</strong> comes from sampling a normal distribution, 
                so as the <span class="mono">degrees of freedom</span> increase the curve becomes taller, the tails 
                become smaller, and we approach the normal distribution. 
                               
              </p>
            </div>
            <div>
              <h3>
                <!-- nineteenth paragraph -  generalized normal distribution(2.5?,1,2) -->
                finally normal
              </h3>
              <p>
                <!-- as we increase the degrees of freedoms in the t distribution we approach the  -->
                the <strong>t-distribution</strong> is sampled from the <strong>normal distribution</strong>,
                 which is a parameterization of the <strong>generalized normal distribution</strong> with the <span class="mono">shape=2</span>,
                so we just have two parameters <span class="mono">location</span> and <span class="mono">scale</span>.
              </p>
              <p> 
              by changing the <span class="mono">location</span> parameter (moving the peak of the graph left or right) 
              we can make more parametrizations of the <strong>normal distribution</strong> with one special one to remember
               - the <strong>standard normal distribution</strong>,
              this is only when <span class="mono">location=0</span>
              and <span class="mono">scale=1</span>
              </p>
            </div>
            <div>
              <h3>
                <!-- twentieth paragraph -  chi(2) -->
                only positive
              </h3>
              <p>
                the <strong>chi distribution</strong> is the absolute value of the <strong>standard normal distribution</strong>, 
                its also the square root of the <strong>chi-squared distribution</strong>.
                like the <strong>chi-squared distribution</strong> the <strong>chi distribution</strong> has one parameter 
                <span class="mono">degrees of freedom</span>, here <span class="mono">degrees of freedom=2</span>
              </p>
              <p> 
                while the <strong>chi-squared distribution</strong> is a parametrization of the <strong>gamma distribution</strong>,
                it is also the sum of squared <strong>normal distributions</strong>. the <strong>chi distribution</strong> 
                is the square root of that sum.
              </p>
              <!-- <p>the chi-squared happens a lot? idk... add more here </p> -->
            </div>
            <div>
              <h3>
                <!-- twenty first paragraph -  nakagami(1,3) -->
                chi-scaled
              </h3>
              <p>
                the <strong>nakagami distribution</strong>  is a scaled version of a specific parameterization of the chi distribution,
                that has two parameters <span class="mono">shape</span> and <span class="mono">spread</span>, 
                here <span class="mono">shape=1, spread=3</span>
                
              </p>
              <p> 
                the <strong>nakagami distribution</strong> is also the square root of 
                the <strong>gamma distribution</strong> where <span class="mono">scale</span> of the gamma is equal to the 
                <span class="mono">shape/spread</span>  of the <strong>nakagami distribution</strong>.
              </p>
            </div>
            <div>
              <h3>
                <!-- twenty second paragraph -  maxwell-boltzmann(2) -->
                particles-of-chi
              </h3>
              <p>
                an application of the <strong>chi distribution</strong> is the <strong>maxwell-boltzmann distribution</strong>,
                which models the distribution of the speed of particles in a gas at a given temperature.
                <!-- to get from the chi distribution to the chi-squared distribution we square it.  -->
                <!-- to get another chi, we are going to squared it, then take the inverse. -->
              </p>
              <p> 
                the <strong>maxwell-boltzmann distribution</strong> is a transformation of a <strong>chi distribution</strong> with 
                <span class="mono">degrees of freedom=3</span>. it has one parameter <span class="mono">scale</span>, 
                which can be applied in modeling the temperature of a gas. as the <span class="mono">scale</span> increases the gas is hotter 
                and the curve flattens, here the <span class="mono">scale=2</span>, so not that hot.
              </p>
            </div>
            <div>
              <h3>
                <!-- twenty second paragraph -  inverse chi-squared(4) -->
                inverted-chi
              </h3>
              <p>
                to get another distribution in the chi-squared family, we are just going to invert it. this will make the
                <strong>inverse-chi-squared distribution</strong>, 
                like the other chi-squared it has one parameter, <span class="mono">degrees of freedom</span>, 
                right now the <span class="mono">degrees of freedom=4</span>.
              </p>
              <p> 
                this distribution is common in bayesian inference, when we don't know the variance of of a normal distribution.
              </p>
            </div>
            <div>
              <h3>
                <!-- twenty third paragraph -  inverse gamma(2,1) -->
                back to gamma
              </h3>
              <p>
                just as the chi-squared distribution is a parameterization of the gamma, 
                the <strong>inverse-chi-squared</strong> is a parameterization
                of the <strong>inverse-gamma distribution</strong>. 
              </p>
              <p> 
                here we have an <strong>inverse-gamma distribution</strong> with <span class="mono">shape=2</span>
                and the <span class="mono">scale=1</span>.
              </p>
            </div>
            <div>
              <h3>
                <!-- twenty fourth paragraph -  levy(0,1) -->
                another gamma 
              </h3>
              <p>
                the <strong>lÃ©vy distribution</strong> has two parameters <span class="mono">location</span> and <span class="mono">scale</span>. 
                
                if the <span class="mono">location=0</span> it is also a parameterization of the <strong>inverse-gamma distribution</strong> 
                with the <span class="mono">shape=.5</span>, this graph is with parameters <span class="mono">location=1, scale=1</span>.
              </p>
              <p>   
                the <strong>lÃ©vy distribution</strong> has been shown to closely model the frequency of geomagnetic reversals 
                - when magnetic north and south swap places.
              </p>
            </div>
            <div>
              <h3>
                <!-- twenty fifth paragraph -  pareto(1,3) -->
                exponentially important
              </h3>
              <p>
                the 80-20 rule comes from the <strong>pareto distribution</strong>, 
                which is the <strong>exponential distribution</strong> raise it to the exponential function.
                
              </p>
              <p>pareto(scale, shape)= scale * <var>e <sup>exponential(rate)</sup></var></p>
              <p> 
                <strong>pareto distribution</strong> has two parameters - <span class="mono">scale</span> 
                and <span class="mono">shape</span>. the <span class="mono">scale</span> is also known as the minimum
                x value, here the <span class="mono">scale=1</span>, so the x-value on the left side of the graph is 1.
                the <span class="mono">shape</span> is known as the pareto index, here <span class="mono">shape=3</span>,
                which is the starting value on the y-axis.
              </p>
              <p>
                the <strong>pareto distribution</strong> is also a continuous version of the <strong>zeta distribution</strong>
                used in <strong>zipf's law</strong>, which is worth a google.
              </p>
            </div>
            <div>
              <h3>
                <!-- twenty sixth paragraph -  lomax(1,2) -->
                not as important...
              </h3>
              <p>
                 the <strong>lomax distribution</strong> is a subset of the <strong>pareto distribution</strong> and not as famous.
                 like the <strong>pareto distribution</strong> it is used in economics as well as modeling internet traffic.
                 it has two parameters - <span class="mono">scale=2</span>, and <span class="mono">shape=1</span> here.
              </p>
              <p> 
                the <strong>lomax distribution</strong> is also equal to the <strong>f distribution</strong>
                in a specific case. 
              </p>
            </div>
            <div>
              <h3>
                <!-- twenty seventh paragraph -  burr(1,1) -->
                part of the family
              </h3>
              <p>
                the <strong>burr distribution</strong> is another distribution used in economics, 
                and is a case of the <strong>lomax distribution</strong> 
                with two paramters <span class="mono">c</span> and <span class="mono">k</span>.
              </p>
              <p> 
                when <span class="mono">c=1</span> the <strong>burr distribution</strong> is the 
                <strong>lomax distribution</strong>. here <span class="mono">c=1</span> 
                and <span class="mono">c=2</span>, so this graph is very similar to the one we made with
                above. 
              </p>
            </div>
            <div>
              <h3>
                <!-- twenty eighth paragraph -  logistic(2,1) -->
                <!-- maybe do 1,1 to talk about logit normal after -->
                logistically
              </h3>
              <p>
                going from the pareto family of distributions whose log is an <strong>exponential distribution</strong> 
                to the log of the <strong>ratio of exponentials</strong> creates the <strong>logistic distribution</strong>.
              </p>
              <p>
                the <strong>logistic distribution</strong> has two paramters
                <span class="mono">location</span> and <span class="mono">scale</span>, we set
                <span class="mono">location=2</span> and <span class="mono">scale=1</span> for this graph.
              </p>
              <p> 
                the logstic function that is used to make this distribution shows up everywhere 
                in machine learning. here is what the standard logistic function looks like
              </p>
              <p>
                logistic function = 1 / ( 1 + <var>e <sup>-x</sup></var> )
              </p>
            </div>
            <div>
              <h3>
                <!-- twenty ninth paragraph -  logit-normal(1,1) -->
                logit again 
              </h3>
              <p>
                if we apply the logistic function we made above to the <strong>normal distribution</strong> we can make 
                the <strong>logit-normal distribution</strong>, with <span class="mono">location=1</span> and
                <span class="mono">scale=1</span> parameters.
              </p>
              <p> 
                the <strong>logit-normal distribution</strong> can be used in place of the 
                <strong>dirichlet distribution</strong>, because it's a little more simple to make.
              </p>
            </div>
            <div>
              <h3>
                <!-- thirty paragraph -  beta prime(2,3) -->
                prime ratios
              </h3>
              <p>
                we made the <strong>logistic distribution</strong> by taking the 
                ratio of <strong>exponential distributions</strong>, 
                if we take the ratio of two <strong>gamma distributions</strong> with the
                <span class="mono">scale=1</span> we get the <strong>beta prime distribution</strong>.
              </p>
              <p> 
                the two <span class="mono">shape</span> parameters from the <strong>gamma distributions</strong>
                are equal to the two parameters of the <strong>beta prime distribution</strong>, here they are 
                <span class="mono">shape=2</span> and <span class="mono">shape=3</span>.
              </p>
            </div>
            <div>
              <h3>
                <!-- thirty first paragraph -  dagum(1,3,1) -->
                special primes
              </h3>
              <p>
                a special case of the <strong>beta prime distribution</strong> is the <strong>dagum distribution</strong>,
                which has 3 parameters, two for <span class="mono">shape</span> and one for <span class="mono">scale</span>.
              </p>
              <p> 
                here <span class="mono">shape=1, shape=3</span>, and <span class="mono">scale=1</span>
                the <strong>dagum distribution</strong> is used in economics and is also related to the 
                gini index.
              </p>
            </div>
            <div>
              <h3>
                <!-- thirty second paragraph - log logistic(1,2) -->
                logs of logs
              </h3>
              <p>
                by setting the first <span class="mono">shape</span> parameter of the <strong>dagum distribution</strong>
                to 1, we can make the, 
                 <strong>log-logistic distribution</strong> with two parameters, <span class="mono">scale</span> and <span class="mono">shape</span>
              </p>
              <p> 
                this the first of three <strong>log distributions</strong> we will talk about. we can make these by taking a distribution we know and raise it to the exponential function. 
                so to make the <strong>log-logistic distribution</strong> we raise <strong>logistic distribution</strong> to the exponential function.
                <!-- normally written as exp() -->
              </p>
              <p>
                log-logistic(scale, shape)=<var>e<sup>logistic(location, scale)</sup></var>
              </p>
            </div>
            <div>
              <h3>
                <!-- thirty third paragraph -  log normal(0,1) -->
                pretty normal
              </h3>
              <p>
                the <strong>log-normal distribution</strong> has two parameters <span class="mono">location</span> and <span class="mono">scale</span>,
                its used everywhere in engineering and economics. 
              </p>
              <p> 
                to get back to the <strong>normal distribution</strong> from the <strong>log-normal distribution</strong>
                we take the natural log of the <strong>log-normal distribution</strong>, basically undoing the logs.           
              </p>
              <p>
                <strong>normal</strong>(location, scale) = ln( <strong>log-normal</strong>(location, scale) )
              </p>
            </div>
            <div>
              <h3>
                <!-- thirty fourth paragraph - log cauchy(0,1) -->
                logs of them
              </h3>
              <p>
                taking the exponential function of the <strong>cauchy distribution</strong> gets us to the last
                distribution we will talk about with a log in the name, the <strong>log-cauchy distribution</strong>.
                like the <strong>cauchy distribution</strong> it has two parameters - <span class="mono">location</span> and <span class="mono">scale</span>.
              </p>
              <p> 
                <strong>log-cauchy distribution</strong> is a heavy tail distribution, mainly cause it is logarithmically decaying. 
              </p>
            </div>
            <div>
              <h3>
                <!-- thirty fifth paragraph - gumbel(1,2) -->
                getting extreme
              </h3>
              <p> 
                 the next three distributions we are going to make by taking the negative log (or natural log) of a distribution we have already seen. if we take the negative log of the  <strong>exponential distribution</strong> with the <span class="mono">rate=1</span> we get the <strong>gumbel distribution</strong>.
              </p>
              <p>gumbel(location, 1) = - log( exponential(1) )</p>
              <p> 
                the <strong>gumbel distribution</strong> has two parameters, the <span class="mono">location</span> and <span class="mono">scale</span>, here the <span class="mono">location=1</span> and <span class="mono">scale=2</span>.
              </p>
            </div>
            <div>
              <h3>
                <!-- thirty sixth paragraph - frÃ©chet(2,1,0)-->
                from the uniform
              </h3>
              <p> 
                the <strong>frÃ©chet distribution</strong> is built from taking the negative log of the <strong>uniform distribution</strong> and has three parameters <span class="mono">shape</span>, <span class="mono">scale</span> and <span class="mono">location of minimum</span>.
              </p>
              <p>
                frÃ©chet(shape, scale, location) = location + scale * <var>(- log ( uniform(0,1) ) ) <sup>- (1 / shape)</sup></var>
              </p>
              <p> 
                the formula looks more complicated than the gumbel, but we normally set the <span class="mono">scale=1</span> and <span class="mono">location of minimum=0</span>, so the formula ends up being... 
              </p>
              <p>
                frÃ©chet(shape, scale, location) = <var>(- log ( uniform(0,1) ) ) <sup>- (1 / shape)</sup></var>
              </p>
              <p> 
                or just the negative log of the <strong>uniform distribution</strong> raised to negative inverse of the shape parameter, here <span class="mono">shape=2</span>, <span class="mono">scale=1</span> and <span class="mono">location of minimum=0</span>
              </p>
            </div>
            <div>
              <h3>
                <!-- thirty seventh paragraph - weibull(1,1) -->
                the last log
              </h3>
              <p> 
                 the last distribution we will build is with the negative natural log and is called the <strong>weibull distribution</strong>. it is very similar to the <strong>frÃ©chet distribution</strong>, but only has two parameters <span class="mono">scale</span> and <span class="mono">shape</span>.
  
              </p>
              <p>
                weibull(scale, shape) = scale * <var>(- ln ( uniform(0,1) ) ) <sup>(1 / shape)</sup></var>
              </p>
              <p> 
                here the <span class="mono">scale=1</span> and <span class="mono">shape=1</span>. the <strong>gumbel</strong>, <strong>frÃ©chet</strong>, and <strong>weibull distributions</strong> are all extreme value distributions used in predicting when extreme weather events (like floods) will occur.
              </p>
            </div>  
            <div>
              <h3>
                <!-- thirty eighth paragraph -  none -->
                <!-- placeholder -->
                ...
              </h3>
              <p>
                <!-- -->
              </p>
              <p> 
                <!-- -->                
              </p>
            </div>        
        </div>
    </div>
    
<h1>more to come</h1>

<script src="../assets/lib/d3v4+jetpack.js"></script>
<script src="../assets/lib/graph-scroll.js"></script>
<script>
  var oldWidth = 0
  function render(){
    if (oldWidth == innerWidth) return
    oldWidth = innerWidth

  // set the correct width and height for the graph
    var width = height = d3.select('#graph').node().offsetWidth
    var r = 30

    if (innerWidth <= 925){
      width = innerWidth
      height = innerHeight*.7
    }

  //  select the graph tag for the svg element
  var svg = d3.select('#graph').html('')
  .append('svg')
      .attrs({width: width, height: height})

  // need to find line attrs to start
  // add a line, with svg 'path'
  var path = svg.append('path')

  var xScale = d3.scaleLinear()
          .domain([0, 20]) // input
          .range([0, width]); // output

  var yScale = d3.scaleLinear()
      .domain([0, .6]) // input 
      .range([height, 0]); // output 

  // gamma 1,2
  var dataset = [{x : 5.000000000000000278e-02, y : 4.876499999999999724e-01},
  {x : 1.300000000000000044e+00, y : 2.610199999999999743e-01},
  {x : 2.549999999999999822e+00, y : 1.397200000000000109e-01},
  {x : 3.799999999999999822e+00, y : 7.477999999999999925e-02},
  {x : 5.049999999999999822e+00, y : 4.003000000000000308e-02},
  {x : 6.299999999999999822e+00, y : 2.143000000000000113e-02},
  {x : 7.549999999999999822e+00, y : 1.146999999999999929e-02},
  {x : 8.800000000000000711e+00, y : 6.139999999999999625e-03},
  {x : 1.005000000000000071e+01, y : 3.289999999999999956e-03},
  {x : 1.130000000000000071e+01, y : 1.760000000000000063e-03},
  {x : 1.255000000000000071e+01, y : 9.399999999999999719e-04},
  {x : 1.380000000000000071e+01, y : 5.000000000000000104e-04},
  {x : 1.505000000000000071e+01, y : 2.700000000000000035e-04},
  {x : 1.630000000000000071e+01, y : 1.399999999999999877e-04},
  {x : 1.755000000000000071e+01, y : 8.000000000000000654e-05},
  {x : 1.955000000000000071e+01, y : 3.000000000000000076e-05}] 

  // console.log(dataset)
  var line = svg
    .append("path")
      .datum(dataset)
      .attr("d", d3.line()
        .x(function(d) { return xScale(d.x) })
        .y(function(d) { return yScale(d.y) })
        .curve(d3.curveMonotoneX)
      )
      .attr("stroke", "black")
      .style("stroke-width", 1)
      .style("fill", "none")

  // colors for each new div in the class='sections' div
  // take out first blue, probably no green
  var colors = ["#C86753", "#C86753", 'steelblue', '#6776d1', '#0f606b', 'black', "#296b0f", 'steelblue', '#6776d1',
                "#C86753", "#C86753", 'steelblue', '#6776d1', "#C86753", "#C86753", 'steelblue', '#6776d1', '#0f606b', 'black',
                "#C86753", "#C86753", 'steelblue', '#6776d1', "#C86753", "#C86753", 'steelblue', '#6776d1', '#0f606b', 'black',
                "#C86753", "#C86753", 'steelblue', '#6776d1', "#C86753", "#C86753", 'steelblue', '#6776d1', '#0f606b', 'black',
                "#C86753", "#C86753", 'steelblue']

  // for the line 
  var gs = d3.graphScroll()
      .container(d3.select('.container-1')) // only for the container-1 class
      .graph(d3.selectAll('container-1 #graph'))
      .eventId('uniqueId1')  // namespace for scroll and resize events
      .sections(d3.selectAll('.container-1 #sections > div'))
      // .offset(innerWidth < 900 ? innerHeight - 30 : 200)
      // when the paragraph div is 'active'
      .on('active', function(i){

    var xScale = d3.scaleLinear()
        .domain([0, 20]) // input
        .range([0, width]); // output

    var yScale = d3.scaleLinear()
        .domain([0, .6]) 
        .range([height, 0]); 

    var xScale_beta = d3.scaleLinear()
        .domain([0,1])
        .range([0, width]);
    
    var yScale_beta = d3.scaleLinear()
        .domain([0, 4])
        .range([height, 0]);
    
    var xScale_f = d3.scaleLinear()
        .domain([0,5])
        .range([0, width]);
    
    var yScale_f = d3.scaleLinear()
        .domain([0, 2])
        .range([height, 0]);

  // gamma 1,2 - gamma 2,2 - gamma 3,2 -gamma 1,2 - expo 1 - erlang 2,2 - chi 6 - chi 8 - 
  // beta 4,6 - beta 3,2 - beta 1,1 - beta .5,.5 - beta .5,.5
  d3.json("../assets/data/distributions.json", function(error, new_y) {

  line
    .datum(new_y[i])
    .transition()
    .duration(1000)
    .attr("d", d3.line()
          .x(function(d) { 
            {
              // if 20 support is (0,5)  aka xScale_f
              if (new_y[i].length === 20) {
                return xScale_f(d.x);
              }
              else if (new_y[i].length >17) {
                return xScale_beta(d.x);
              }
              else {
                return xScale(d.x); 
              }
              };
            })
          .y(function(d) { 
            if (new_y[i].length === 20) {
              return yScale_f(d.y);
            }
            else if (new_y[i].length >17){
              return yScale_beta(d.y);
            }
            else {
              return yScale(d.y);
            }
            })
          .curve(d3.curveMonotoneX)
      )
    .attr("stroke", colors[i])
       .style("stroke-width", 1)
     .style("fill", "none")
      })
    });
  d3.select('#source')
      .styles({'margin-bottom': window.innerHeight - 450 + 'px', padding: '150px'})
}
  render()
  d3.select(window).on('resize', render)

  function scrollToTop() {
    var position =
        document.body.scrollTop || document.documentElement.scrollTop;
    if (position) {
        window.scrollBy(0, -Math.max(1, Math.floor(position / 10)));
        scrollAnimation = setTimeout("scrollToTop()", 30);
    } else clearTimeout(scrollAnimation);
}
</script>
<footer>
  <div id="end">
    <div><a href="#top" onclick="scrollToTop(); return false">distributions</a></div>
    <div><a href="../ns-the-details/">the details</a></div>
    <div><a href="../">site</a></div>
  </div>
</footer>
</body>